{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a93366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203d5f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('Event_Context.json', 'r') as fin:\n",
    "    data = json.loads(fin.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82a53922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>When</th>\n",
       "      <th>Main Page</th>\n",
       "      <th>Address1</th>\n",
       "      <th>Address2</th>\n",
       "      <th>thumb</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PGL Wallachia S3</td>\n",
       "      <td>Full information about PGL Wallachia S3 Dota 2...</td>\n",
       "      <td>Mar 8</td>\n",
       "      <td>Sat, Mar 8</td>\n",
       "      <td>https://ggscore.com/en/dota-2/pgl-wallachia-se...</td>\n",
       "      <td>PGL ESPORTS, Bulevardul Dimitrie Pompeiu 9-9A</td>\n",
       "      <td>Bucharest, Romania</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLAST Slam #3</td>\n",
       "      <td>Full information about BLAST Slam #3 Dota 2. M...</td>\n",
       "      <td>May 5</td>\n",
       "      <td>Mon, May 5</td>\n",
       "      <td>https://ggscore.com/en/dota-2/blast-slam-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Title                                               Desc  \\\n",
       "0  PGL Wallachia S3  Full information about PGL Wallachia S3 Dota 2...   \n",
       "1     BLAST Slam #3  Full information about BLAST Slam #3 Dota 2. M...   \n",
       "\n",
       "  Start Date        When                                          Main Page  \\\n",
       "0      Mar 8  Sat, Mar 8  https://ggscore.com/en/dota-2/pgl-wallachia-se...   \n",
       "1      May 5  Mon, May 5         https://ggscore.com/en/dota-2/blast-slam-3   \n",
       "\n",
       "                                        Address1            Address2  \\\n",
       "0  PGL ESPORTS, Bulevardul Dimitrie Pompeiu 9-9A  Bucharest, Romania   \n",
       "1                                            NaN                 NaN   \n",
       "\n",
       "                                               thumb  \\\n",
       "0  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
       "1  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
       "\n",
       "                                               image  \n",
       "0  https://encrypted-tbn0.gstatic.com/images?q=tb...  \n",
       "1  https://encrypted-tbn0.gstatic.com/images?q=tb...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Final_Events.csv')\n",
    "df.head(n = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc93cdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = list(data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25993d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df['Desc'].fillna(value = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3886b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from time import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9471bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorization done in 0.022 s\n",
      "n_samples: 489, n_features: 308\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.5,\n",
    "    min_df=5,\n",
    "    stop_words=\"english\",\n",
    ")\n",
    "t0 = time()\n",
    "X_tfidf = vectorizer.fit_transform(documents)\n",
    "\n",
    "print(f\"vectorization done in {time() - t0:.3f} s\")\n",
    "print(f\"n_samples: {X_tfidf.shape[0]}, n_features: {X_tfidf.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc042fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023\n"
     ]
    }
   ],
   "source": [
    "print(f\"{X_tfidf.nnz / np.prod(X_tfidf.shape):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90e7dfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorization done in 5.623 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "lsa_vectorizer = make_pipeline(\n",
    "    HashingVectorizer(stop_words=\"english\", n_features=50_000),\n",
    "    TfidfTransformer(),\n",
    "    TruncatedSVD(n_components=100, random_state=0),\n",
    "    Normalizer(copy=False),\n",
    ")\n",
    "\n",
    "t0 = time()\n",
    "X_hashed_lsa = lsa_vectorizer.fit_transform(documents)\n",
    "print(f\"vectorization done in {time() - t0:.3f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fac05a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(489, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hashed_lsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32d80173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements assigned to each cluster: [140  55 122 172]\n",
      "Number of elements assigned to each cluster: [ 89 245 112  43]\n",
      "Number of elements assigned to each cluster: [134  71  48 236]\n",
      "Number of elements assigned to each cluster: [110  47 122 210]\n",
      "Number of elements assigned to each cluster: [251  99  49  90]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "for seed in range(5):\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=4,\n",
    "        max_iter=100,\n",
    "        n_init=5,\n",
    "        random_state=seed,\n",
    "    ).fit(X_hashed_lsa)\n",
    "    cluster_ids, cluster_sizes = np.unique(kmeans.labels_, return_counts=True)\n",
    "    print(f\"Number of elements assigned to each cluster: {cluster_sizes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eb1bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [(kmeans.labels_[idx], d) for idx, d in enumerate(documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a854b7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73599270",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ce6b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unqiue_sets = []\n",
    "for idx in range(max(kmeans.labels_) + 1):\n",
    "    current_docs = [d for label, d in clusters if label == idx]\n",
    "    all_words    = set([word for document in current_docs for word in tokenizer.tokenize(document)])\n",
    "    unqiue_sets.append(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04f4219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1,s2,s3,s4 = unqiue_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5614d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
